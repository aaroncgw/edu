{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Midterm 2\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors: W. Pan, P. Protopapas, K. Rader**<br>\n",
    "**Due Date: ** Tuesday, November 22nd, 2016 at 12:00pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "from sklearn.linear_model import LogisticRegressionCV as LogRegCV\n",
    "from sklearn import ensemble\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Diagnosing the Semian Flu 2016\n",
    "\n",
    "You are given the early data for an outbreak of a dangerous virus originating from a group of primates being keeped in a Massechussetts biomedical research lab, this virus is dubbed the \"Semian Flu\".\n",
    "\n",
    "You have the medical records of $n$ number of patients in `'flu_train.csv`. There are two general types of patients in the data, flu patients and healthy (this is recorded in the column labeled `flu`, a 0 indicates the absences of the virus and a 1 indicates presence). Furthermore, scientists have found that there are two strains of the virus, each requiring a different type of treatment (this is recorded in the column labeled `flutype`, a 1 indicates the absences of the virus, a 1 indicates presence of strain 1 and a 2 indicates the presence of strain 2).\n",
    "\n",
    "**Your task:** build a model to predict if a given patient has the flu. Your goal is to catch as many flu patients as possible without misdiagnosing too many healthy patients.\n",
    "\n",
    "**The deliverable:** a function called `flu_predict` which satisfies:\n",
    "\n",
    "- input: `x_test`, a set of medical predictors for a group of patients\n",
    "- output: `y_pred`, a set of labels, one for each patient; 0 for healthy and 1 for infected with the flu virus\n",
    "\n",
    "The MA state government will use your model to diagnose sets of future patients (held by us). You can expect that there will be an increase in the number of flu patients in any groups of patients in the future.\n",
    "\n",
    "We provide you with some benchmarks for comparison.\n",
    "\n",
    "**Baseline Model:** \n",
    "- ~50% expected accuracy on healthy patients in observed data\n",
    "- ~50% expected accuracy on flu patients in observed data\n",
    "- ~50% expected accuracy on healthy patients in future data \n",
    "- ~50% expected accuracy on flu patients in future data\n",
    "- time to build: 5 min\n",
    "\n",
    "**Reasonable Model:** \n",
    "- ~69% expected accuracy on healthy patients in observed data\n",
    "- ~55% expected accuracy on flu patients, in observed data\n",
    "- ~69% expected accuracy on healthy patients in observed data\n",
    "- ~60% expected accuracy on flu patients, in observed data\n",
    "- time to build: 20 min\n",
    "\n",
    "**Grading:**\n",
    "Your grade will be based on:\n",
    "1. your model's ability to out-perform our benchmarks\n",
    "2. your ability to carefully and thoroughly follow the data science pipeline (see lecture slides for definition)\n",
    "3. the extend to which all choices are reasonable and defensible by methods you have learned in this class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't know what exactly is meant by \"data science pipeline\" is - I had previously merged all the lecture sides into two large pdf's, splitting the course in two essentially and the only location I can find the text \"pipe\" is in the very first lecture and it is only a side reference. I guess it could have been in one of the html \"slides\", didn't have time to digging through those. I wanted to try out some visualizations but didn't have time - and by that point they would have been added in after everything was done, somewhat defeating the purpose.  \n",
    "\n",
    "My background is currently in data engineering and as you'll see below, the source data is my biggest concernt. For Midterm I the details were fantastical and there wasn't anything to really be done with the data anyway. Now that we have a more realistic example, and we've done more discussion of ethics etc. in class, the real answer to this question is to of course 1) void my contract with the state of MA, and 2) move out of MA cause state officials don't know what they are doing in hiring me. But more seriously, I truly believe that at least 80% of the work below should have been concentrated on reviewing and cleaning the data vs. actually creating the models. That estimate is given my lack of domain knowledge - I suspect with more background in the biostatistics world I should spend even more time on data prep and cleaning. Anyway, I spent some time initial on the data side but decided I couldn't do anything too worthwhile there given time constraints and moved on to the more basic tasks requested.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeDecade</th>\n",
       "      <th>AgeMonths</th>\n",
       "      <th>Race1</th>\n",
       "      <th>Race3</th>\n",
       "      <th>Education</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HHIncome</th>\n",
       "      <th>...</th>\n",
       "      <th>HardDrugs</th>\n",
       "      <th>SexEver</th>\n",
       "      <th>SexAge</th>\n",
       "      <th>SexNumPartnLife</th>\n",
       "      <th>SexNumPartYear</th>\n",
       "      <th>SameSex</th>\n",
       "      <th>SexOrientation</th>\n",
       "      <th>PregnantNow</th>\n",
       "      <th>flu</th>\n",
       "      <th>flutype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 51624</td>\n",
       "      <td>   male</td>\n",
       "      <td> 34</td>\n",
       "      <td>  30-39</td>\n",
       "      <td> 409</td>\n",
       "      <td> White</td>\n",
       "      <td> NaN</td>\n",
       "      <td>  High School</td>\n",
       "      <td>     Married</td>\n",
       "      <td> 25000-34999</td>\n",
       "      <td>...</td>\n",
       "      <td> Yes</td>\n",
       "      <td> Yes</td>\n",
       "      <td> 16</td>\n",
       "      <td>  8</td>\n",
       "      <td>  1</td>\n",
       "      <td>  No</td>\n",
       "      <td> Heterosexual</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 51630</td>\n",
       "      <td> female</td>\n",
       "      <td> 49</td>\n",
       "      <td>  40-49</td>\n",
       "      <td> 596</td>\n",
       "      <td> White</td>\n",
       "      <td> NaN</td>\n",
       "      <td> Some College</td>\n",
       "      <td> LivePartner</td>\n",
       "      <td> 35000-44999</td>\n",
       "      <td>...</td>\n",
       "      <td> Yes</td>\n",
       "      <td> Yes</td>\n",
       "      <td> 12</td>\n",
       "      <td> 10</td>\n",
       "      <td>  1</td>\n",
       "      <td> Yes</td>\n",
       "      <td> Heterosexual</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 51638</td>\n",
       "      <td>   male</td>\n",
       "      <td>  9</td>\n",
       "      <td>    0-9</td>\n",
       "      <td> 115</td>\n",
       "      <td> White</td>\n",
       "      <td> NaN</td>\n",
       "      <td>          NaN</td>\n",
       "      <td>         NaN</td>\n",
       "      <td> 75000-99999</td>\n",
       "      <td>...</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>          NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 51646</td>\n",
       "      <td>   male</td>\n",
       "      <td>  8</td>\n",
       "      <td>    0-9</td>\n",
       "      <td> 101</td>\n",
       "      <td> White</td>\n",
       "      <td> NaN</td>\n",
       "      <td>          NaN</td>\n",
       "      <td>         NaN</td>\n",
       "      <td> 55000-64999</td>\n",
       "      <td>...</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>          NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 51647</td>\n",
       "      <td> female</td>\n",
       "      <td> 45</td>\n",
       "      <td>  40-49</td>\n",
       "      <td> 541</td>\n",
       "      <td> White</td>\n",
       "      <td> NaN</td>\n",
       "      <td> College Grad</td>\n",
       "      <td>     Married</td>\n",
       "      <td> 75000-99999</td>\n",
       "      <td>...</td>\n",
       "      <td>  No</td>\n",
       "      <td> Yes</td>\n",
       "      <td> 13</td>\n",
       "      <td> 20</td>\n",
       "      <td>  0</td>\n",
       "      <td> Yes</td>\n",
       "      <td>     Bisexual</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Gender  Age AgeDecade  AgeMonths  Race1 Race3     Education  \\\n",
       "0  51624    male   34     30-39        409  White   NaN   High School   \n",
       "1  51630  female   49     40-49        596  White   NaN  Some College   \n",
       "2  51638    male    9       0-9        115  White   NaN           NaN   \n",
       "3  51646    male    8       0-9        101  White   NaN           NaN   \n",
       "4  51647  female   45     40-49        541  White   NaN  College Grad   \n",
       "\n",
       "  MaritalStatus     HHIncome   ...     HardDrugs  SexEver  SexAge  \\\n",
       "0       Married  25000-34999   ...           Yes      Yes      16   \n",
       "1   LivePartner  35000-44999   ...           Yes      Yes      12   \n",
       "2           NaN  75000-99999   ...           NaN      NaN     NaN   \n",
       "3           NaN  55000-64999   ...           NaN      NaN     NaN   \n",
       "4       Married  75000-99999   ...            No      Yes      13   \n",
       "\n",
       "  SexNumPartnLife SexNumPartYear  SameSex  SexOrientation  PregnantNow  flu  \\\n",
       "0               8              1       No    Heterosexual          NaN    0   \n",
       "1              10              1      Yes    Heterosexual          NaN    0   \n",
       "2             NaN            NaN      NaN             NaN          NaN    0   \n",
       "3             NaN            NaN      NaN             NaN          NaN    0   \n",
       "4              20              0      Yes        Bisexual          NaN    0   \n",
       "\n",
       "   flutype  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load up the two datasets and inspect\n",
    "train = pd.read_csv('flu_train.csv', low_memory=False)  # low memory is set false for better type inference\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeDecade</th>\n",
       "      <th>AgeMonths</th>\n",
       "      <th>Race1</th>\n",
       "      <th>Race3</th>\n",
       "      <th>Education</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HHIncome</th>\n",
       "      <th>...</th>\n",
       "      <th>RegularMarij</th>\n",
       "      <th>AgeRegMarij</th>\n",
       "      <th>HardDrugs</th>\n",
       "      <th>SexEver</th>\n",
       "      <th>SexAge</th>\n",
       "      <th>SexNumPartnLife</th>\n",
       "      <th>SexNumPartYear</th>\n",
       "      <th>SameSex</th>\n",
       "      <th>SexOrientation</th>\n",
       "      <th>PregnantNow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 51625</td>\n",
       "      <td>   male</td>\n",
       "      <td>  4</td>\n",
       "      <td>    0-9</td>\n",
       "      <td>  49</td>\n",
       "      <td> Other</td>\n",
       "      <td> NaN</td>\n",
       "      <td>          NaN</td>\n",
       "      <td>     NaN</td>\n",
       "      <td> 20000-24999</td>\n",
       "      <td>...</td>\n",
       "      <td> NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>          NaN</td>\n",
       "      <td> NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 51678</td>\n",
       "      <td>   male</td>\n",
       "      <td> 60</td>\n",
       "      <td>  60-69</td>\n",
       "      <td> 721</td>\n",
       "      <td> White</td>\n",
       "      <td> NaN</td>\n",
       "      <td>  High School</td>\n",
       "      <td> Married</td>\n",
       "      <td> 15000-19999</td>\n",
       "      <td>...</td>\n",
       "      <td> NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  No</td>\n",
       "      <td> Yes</td>\n",
       "      <td> 20</td>\n",
       "      <td>  1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  No</td>\n",
       "      <td>          NaN</td>\n",
       "      <td> NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 51694</td>\n",
       "      <td>   male</td>\n",
       "      <td> 38</td>\n",
       "      <td>  30-39</td>\n",
       "      <td> 458</td>\n",
       "      <td> White</td>\n",
       "      <td> NaN</td>\n",
       "      <td> Some College</td>\n",
       "      <td> Married</td>\n",
       "      <td> 20000-24999</td>\n",
       "      <td>...</td>\n",
       "      <td>  No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  No</td>\n",
       "      <td> Yes</td>\n",
       "      <td> 23</td>\n",
       "      <td>  1</td>\n",
       "      <td>  1</td>\n",
       "      <td>  No</td>\n",
       "      <td> Heterosexual</td>\n",
       "      <td> NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 51695</td>\n",
       "      <td>   male</td>\n",
       "      <td>  8</td>\n",
       "      <td>    0-9</td>\n",
       "      <td> 104</td>\n",
       "      <td> White</td>\n",
       "      <td> NaN</td>\n",
       "      <td>          NaN</td>\n",
       "      <td>     NaN</td>\n",
       "      <td> 65000-74999</td>\n",
       "      <td>...</td>\n",
       "      <td> NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>          NaN</td>\n",
       "      <td> NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 51711</td>\n",
       "      <td> female</td>\n",
       "      <td> 59</td>\n",
       "      <td>  50-59</td>\n",
       "      <td> 718</td>\n",
       "      <td> Other</td>\n",
       "      <td> NaN</td>\n",
       "      <td>    8th Grade</td>\n",
       "      <td> Widowed</td>\n",
       "      <td> 20000-24999</td>\n",
       "      <td>...</td>\n",
       "      <td> NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>          NaN</td>\n",
       "      <td> NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Gender  Age AgeDecade  AgeMonths  Race1 Race3     Education  \\\n",
       "0  51625    male    4       0-9         49  Other   NaN           NaN   \n",
       "1  51678    male   60     60-69        721  White   NaN   High School   \n",
       "2  51694    male   38     30-39        458  White   NaN  Some College   \n",
       "3  51695    male    8       0-9        104  White   NaN           NaN   \n",
       "4  51711  female   59     50-59        718  Other   NaN     8th Grade   \n",
       "\n",
       "  MaritalStatus     HHIncome     ...       RegularMarij  AgeRegMarij  \\\n",
       "0           NaN  20000-24999     ...                NaN          NaN   \n",
       "1       Married  15000-19999     ...                NaN          NaN   \n",
       "2       Married  20000-24999     ...                 No          NaN   \n",
       "3           NaN  65000-74999     ...                NaN          NaN   \n",
       "4       Widowed  20000-24999     ...                NaN          NaN   \n",
       "\n",
       "   HardDrugs SexEver SexAge  SexNumPartnLife  SexNumPartYear  SameSex  \\\n",
       "0        NaN     NaN    NaN              NaN             NaN      NaN   \n",
       "1         No     Yes     20                1             NaN       No   \n",
       "2         No     Yes     23                1               1       No   \n",
       "3        NaN     NaN    NaN              NaN             NaN      NaN   \n",
       "4        NaN     NaN    NaN              NaN             NaN      NaN   \n",
       "\n",
       "   SexOrientation  PregnantNow  \n",
       "0             NaN          NaN  \n",
       "1             NaN          NaN  \n",
       "2    Heterosexual          NaN  \n",
       "3             NaN          NaN  \n",
       "4             NaN          NaN  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('flu_test_no_y.csv', low_memory=False)  # low memory is set false for better type inference\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 5,246\n",
      "Size of test set: 1,533\n",
      "Train/test split: 77/23\n",
      "\n",
      "Train/test split is a little more extreme than in some cases but seems reasonable. Given that the split is favored\n",
      " on the train side, we could potentially remove the two predicted Y values from a subset of train and move to test\n",
      " but should be ok as-is.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_size = train.shape[0]\n",
    "test_size = test.shape[0]\n",
    "print 'Size of training set: {:,}'.format(train_size)\n",
    "print 'Size of test set: {:,}'.format(test_size)\n",
    "print 'Train/test split: {:.0f}/{:.0f}'.format(\n",
    "    train_size*1.0/(train_size+test_size)*100, \n",
    "    test_size*1.0/(train_size+test_size)*100)\n",
    "print\n",
    "print 'Train/test split is a little more extreme than in some cases but seems reasonable. Given that the split is favored'\n",
    "print ' on the train side, we could potentially remove the two predicted Y values from a subset of train and move to test'\n",
    "print ' but should be ok as-is.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train has 76 columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ID', 'Gender', 'Age', 'AgeDecade', 'AgeMonths', 'Race1', 'Race3',\n",
       "       'Education', 'MaritalStatus', 'HHIncome', 'HHIncomeMid', 'Poverty',\n",
       "       'HomeRooms', 'HomeOwn', 'Work', 'Weight', 'Length', 'HeadCirc',\n",
       "       'Height', 'BMI', 'BMICatUnder20yrs', 'BMI_WHO', 'Pulse', 'BPSysAve',\n",
       "       'BPDiaAve', 'BPSys1', 'BPDia1', 'BPSys2', 'BPDia2', 'BPSys3',\n",
       "       'BPDia3', 'Testosterone', 'DirectChol', 'TotChol', 'UrineVol1',\n",
       "       'UrineFlow1', 'UrineVol2', 'UrineFlow2', 'Diabetes', 'DiabetesAge',\n",
       "       'HealthGen', 'DaysMentHlthBad', 'LittleInterest', 'Depressed',\n",
       "       'nPregnancies', 'nBabies', 'Age1stBaby', 'SleepHrsNight',\n",
       "       'SleepTrouble', 'PhysActive', 'PhysActiveDays', 'TVHrsDay',\n",
       "       'CompHrsDay', 'TVHrsDayChild', 'CompHrsDayChild', 'Alcohol12PlusYr',\n",
       "       'AlcoholDay', 'AlcoholYear', 'SmokeNow', 'Smoke100', 'Smoke100n',\n",
       "       'SmokeAge', 'Marijuana', 'AgeFirstMarij', 'RegularMarij',\n",
       "       'AgeRegMarij', 'HardDrugs', 'SexEver', 'SexAge', 'SexNumPartnLife',\n",
       "       'SexNumPartYear', 'SameSex', 'SexOrientation', 'PregnantNow', 'flu',\n",
       "       'flutype'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns = train.columns.values\n",
    "print 'train has {} columns'.format(len(train_columns))\n",
    "train_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test has 74 columns, as expected same count as train -2 for the two predicotr columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ID', 'Gender', 'Age', 'AgeDecade', 'AgeMonths', 'Race1', 'Race3',\n",
       "       'Education', 'MaritalStatus', 'HHIncome', 'HHIncomeMid', 'Poverty',\n",
       "       'HomeRooms', 'HomeOwn', 'Work', 'Weight', 'Length', 'HeadCirc',\n",
       "       'Height', 'BMI', 'BMICatUnder20yrs', 'BMI_WHO', 'Pulse', 'BPSysAve',\n",
       "       'BPDiaAve', 'BPSys1', 'BPDia1', 'BPSys2', 'BPDia2', 'BPSys3',\n",
       "       'BPDia3', 'Testosterone', 'DirectChol', 'TotChol', 'UrineVol1',\n",
       "       'UrineFlow1', 'UrineVol2', 'UrineFlow2', 'Diabetes', 'DiabetesAge',\n",
       "       'HealthGen', 'DaysMentHlthBad', 'LittleInterest', 'Depressed',\n",
       "       'nPregnancies', 'nBabies', 'Age1stBaby', 'SleepHrsNight',\n",
       "       'SleepTrouble', 'PhysActive', 'PhysActiveDays', 'TVHrsDay',\n",
       "       'CompHrsDay', 'TVHrsDayChild', 'CompHrsDayChild', 'Alcohol12PlusYr',\n",
       "       'AlcoholDay', 'AlcoholYear', 'SmokeNow', 'Smoke100', 'Smoke100n',\n",
       "       'SmokeAge', 'Marijuana', 'AgeFirstMarij', 'RegularMarij',\n",
       "       'AgeRegMarij', 'HardDrugs', 'SexEver', 'SexAge', 'SexNumPartnLife',\n",
       "       'SexNumPartYear', 'SameSex', 'SexOrientation', 'PregnantNow'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_columns = test.columns.values\n",
    "print 'test has {} columns, as expected same count as train -2 for the two predicotr columns'.format(len(test_columns))\n",
    "test_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns in train but not in test: flutype, flu\n",
      "columns in test but not in train: \n",
      "\n",
      "ok, confirmed, looks like indeed those two flu dependent variables are the only difference\n"
     ]
    }
   ],
   "source": [
    "print 'columns in train but not in test: {}'.format(\n",
    "    ', '.join([col for col in set(train_columns).difference(set(test_columns))]) )\n",
    "print 'columns in test but not in train: {}'.format(\n",
    "    ', '.join([col for col in set(test_columns).difference(set(train_columns))]) )\n",
    "print\n",
    "print 'ok, confirmed, looks like indeed those two flu dependent variables are the only difference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>missing_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td> 5246</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td> 5246</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td> 5246</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeDecade</th>\n",
       "      <td> 5057</td>\n",
       "      <td> 0.036027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeMonths</th>\n",
       "      <td> 2726</td>\n",
       "      <td> 0.480366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race1</th>\n",
       "      <td> 5246</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race3</th>\n",
       "      <td> 2508</td>\n",
       "      <td> 0.521921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td> 3574</td>\n",
       "      <td> 0.318719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaritalStatus</th>\n",
       "      <td> 3580</td>\n",
       "      <td> 0.317575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHIncome</th>\n",
       "      <td> 4798</td>\n",
       "      <td> 0.085398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHIncomeMid</th>\n",
       "      <td> 4798</td>\n",
       "      <td> 0.085398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poverty</th>\n",
       "      <td> 4843</td>\n",
       "      <td> 0.076820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HomeRooms</th>\n",
       "      <td> 5210</td>\n",
       "      <td> 0.006862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HomeOwn</th>\n",
       "      <td> 5213</td>\n",
       "      <td> 0.006291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work</th>\n",
       "      <td> 3889</td>\n",
       "      <td> 0.258673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td> 5206</td>\n",
       "      <td> 0.007625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>  356</td>\n",
       "      <td> 0.932139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeadCirc</th>\n",
       "      <td>   61</td>\n",
       "      <td> 0.988372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td> 5014</td>\n",
       "      <td> 0.044224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td> 5010</td>\n",
       "      <td> 0.044987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMICatUnder20yrs</th>\n",
       "      <td>  724</td>\n",
       "      <td> 0.861990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI_WHO</th>\n",
       "      <td> 4990</td>\n",
       "      <td> 0.048799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulse</th>\n",
       "      <td> 4376</td>\n",
       "      <td> 0.165841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPSysAve</th>\n",
       "      <td> 4369</td>\n",
       "      <td> 0.167175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPDiaAve</th>\n",
       "      <td> 4369</td>\n",
       "      <td> 0.167175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPSys1</th>\n",
       "      <td> 4213</td>\n",
       "      <td> 0.196912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPDia1</th>\n",
       "      <td> 4213</td>\n",
       "      <td> 0.196912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPSys2</th>\n",
       "      <td> 4263</td>\n",
       "      <td> 0.187381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPDia2</th>\n",
       "      <td> 4263</td>\n",
       "      <td> 0.187381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPSys3</th>\n",
       "      <td> 4261</td>\n",
       "      <td> 0.187762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age1stBaby</th>\n",
       "      <td>  941</td>\n",
       "      <td> 0.820625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SleepHrsNight</th>\n",
       "      <td> 3879</td>\n",
       "      <td> 0.260579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SleepTrouble</th>\n",
       "      <td> 3890</td>\n",
       "      <td> 0.258483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActive</th>\n",
       "      <td> 4204</td>\n",
       "      <td> 0.198628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActiveDays</th>\n",
       "      <td> 2374</td>\n",
       "      <td> 0.547465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVHrsDay</th>\n",
       "      <td> 2417</td>\n",
       "      <td> 0.539268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CompHrsDay</th>\n",
       "      <td> 2419</td>\n",
       "      <td> 0.538887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVHrsDayChild</th>\n",
       "      <td>  417</td>\n",
       "      <td> 0.920511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CompHrsDayChild</th>\n",
       "      <td>  417</td>\n",
       "      <td> 0.920511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol12PlusYr</th>\n",
       "      <td> 3232</td>\n",
       "      <td> 0.383912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlcoholDay</th>\n",
       "      <td> 2404</td>\n",
       "      <td> 0.541746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlcoholYear</th>\n",
       "      <td> 2882</td>\n",
       "      <td> 0.450629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SmokeNow</th>\n",
       "      <td> 1539</td>\n",
       "      <td> 0.706634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke100</th>\n",
       "      <td> 3581</td>\n",
       "      <td> 0.317385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke100n</th>\n",
       "      <td> 3581</td>\n",
       "      <td> 0.317385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SmokeAge</th>\n",
       "      <td> 1479</td>\n",
       "      <td> 0.718071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marijuana</th>\n",
       "      <td> 2411</td>\n",
       "      <td> 0.540412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeFirstMarij</th>\n",
       "      <td> 1331</td>\n",
       "      <td> 0.746283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegularMarij</th>\n",
       "      <td> 2411</td>\n",
       "      <td> 0.540412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeRegMarij</th>\n",
       "      <td>  629</td>\n",
       "      <td> 0.880099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HardDrugs</th>\n",
       "      <td> 2798</td>\n",
       "      <td> 0.466641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SexEver</th>\n",
       "      <td> 2796</td>\n",
       "      <td> 0.467022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SexAge</th>\n",
       "      <td> 2673</td>\n",
       "      <td> 0.490469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SexNumPartnLife</th>\n",
       "      <td> 2773</td>\n",
       "      <td> 0.471407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SexNumPartYear</th>\n",
       "      <td> 2405</td>\n",
       "      <td> 0.541555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SameSex</th>\n",
       "      <td> 2798</td>\n",
       "      <td> 0.466641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SexOrientation</th>\n",
       "      <td> 2357</td>\n",
       "      <td> 0.550705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PregnantNow</th>\n",
       "      <td>  883</td>\n",
       "      <td> 0.831681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flu</th>\n",
       "      <td> 5246</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flutype</th>\n",
       "      <td> 5246</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0  missing_prop\n",
       "ID                5246      0.000000\n",
       "Gender            5246      0.000000\n",
       "Age               5246      0.000000\n",
       "AgeDecade         5057      0.036027\n",
       "AgeMonths         2726      0.480366\n",
       "Race1             5246      0.000000\n",
       "Race3             2508      0.521921\n",
       "Education         3574      0.318719\n",
       "MaritalStatus     3580      0.317575\n",
       "HHIncome          4798      0.085398\n",
       "HHIncomeMid       4798      0.085398\n",
       "Poverty           4843      0.076820\n",
       "HomeRooms         5210      0.006862\n",
       "HomeOwn           5213      0.006291\n",
       "Work              3889      0.258673\n",
       "Weight            5206      0.007625\n",
       "Length             356      0.932139\n",
       "HeadCirc            61      0.988372\n",
       "Height            5014      0.044224\n",
       "BMI               5010      0.044987\n",
       "BMICatUnder20yrs   724      0.861990\n",
       "BMI_WHO           4990      0.048799\n",
       "Pulse             4376      0.165841\n",
       "BPSysAve          4369      0.167175\n",
       "BPDiaAve          4369      0.167175\n",
       "BPSys1            4213      0.196912\n",
       "BPDia1            4213      0.196912\n",
       "BPSys2            4263      0.187381\n",
       "BPDia2            4263      0.187381\n",
       "BPSys3            4261      0.187762\n",
       "...                ...           ...\n",
       "Age1stBaby         941      0.820625\n",
       "SleepHrsNight     3879      0.260579\n",
       "SleepTrouble      3890      0.258483\n",
       "PhysActive        4204      0.198628\n",
       "PhysActiveDays    2374      0.547465\n",
       "TVHrsDay          2417      0.539268\n",
       "CompHrsDay        2419      0.538887\n",
       "TVHrsDayChild      417      0.920511\n",
       "CompHrsDayChild    417      0.920511\n",
       "Alcohol12PlusYr   3232      0.383912\n",
       "AlcoholDay        2404      0.541746\n",
       "AlcoholYear       2882      0.450629\n",
       "SmokeNow          1539      0.706634\n",
       "Smoke100          3581      0.317385\n",
       "Smoke100n         3581      0.317385\n",
       "SmokeAge          1479      0.718071\n",
       "Marijuana         2411      0.540412\n",
       "AgeFirstMarij     1331      0.746283\n",
       "RegularMarij      2411      0.540412\n",
       "AgeRegMarij        629      0.880099\n",
       "HardDrugs         2798      0.466641\n",
       "SexEver           2796      0.467022\n",
       "SexAge            2673      0.490469\n",
       "SexNumPartnLife   2773      0.471407\n",
       "SexNumPartYear    2405      0.541555\n",
       "SameSex           2798      0.466641\n",
       "SexOrientation    2357      0.550705\n",
       "PregnantNow        883      0.831681\n",
       "flu               5246      0.000000\n",
       "flutype           5246      0.000000\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look to see which variables are missing a lot of data\n",
    "# create a missing_prop column to hold proportion that are missing values in a given column\n",
    "df_count = pd.DataFrame( train.count())\n",
    "df_count['missing_prop'] = df_count.apply(lambda cnt: 1-(cnt*1.0/train_size))\n",
    "df_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>missing_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Race3</th>\n",
       "      <td> 2508</td>\n",
       "      <td> 0.521921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>  356</td>\n",
       "      <td> 0.932139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeadCirc</th>\n",
       "      <td>   61</td>\n",
       "      <td> 0.988372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMICatUnder20yrs</th>\n",
       "      <td>  724</td>\n",
       "      <td> 0.861990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testosterone</th>\n",
       "      <td> 2008</td>\n",
       "      <td> 0.617232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UrineVol2</th>\n",
       "      <td>  763</td>\n",
       "      <td> 0.854556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UrineFlow2</th>\n",
       "      <td>  763</td>\n",
       "      <td> 0.854556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesAge</th>\n",
       "      <td>  330</td>\n",
       "      <td> 0.937095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nPregnancies</th>\n",
       "      <td> 1283</td>\n",
       "      <td> 0.755433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nBabies</th>\n",
       "      <td> 1182</td>\n",
       "      <td> 0.774685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age1stBaby</th>\n",
       "      <td>  941</td>\n",
       "      <td> 0.820625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActiveDays</th>\n",
       "      <td> 2374</td>\n",
       "      <td> 0.547465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVHrsDay</th>\n",
       "      <td> 2417</td>\n",
       "      <td> 0.539268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CompHrsDay</th>\n",
       "      <td> 2419</td>\n",
       "      <td> 0.538887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVHrsDayChild</th>\n",
       "      <td>  417</td>\n",
       "      <td> 0.920511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CompHrsDayChild</th>\n",
       "      <td>  417</td>\n",
       "      <td> 0.920511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlcoholDay</th>\n",
       "      <td> 2404</td>\n",
       "      <td> 0.541746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SmokeNow</th>\n",
       "      <td> 1539</td>\n",
       "      <td> 0.706634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SmokeAge</th>\n",
       "      <td> 1479</td>\n",
       "      <td> 0.718071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marijuana</th>\n",
       "      <td> 2411</td>\n",
       "      <td> 0.540412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeFirstMarij</th>\n",
       "      <td> 1331</td>\n",
       "      <td> 0.746283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegularMarij</th>\n",
       "      <td> 2411</td>\n",
       "      <td> 0.540412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeRegMarij</th>\n",
       "      <td>  629</td>\n",
       "      <td> 0.880099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SexNumPartYear</th>\n",
       "      <td> 2405</td>\n",
       "      <td> 0.541555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SexOrientation</th>\n",
       "      <td> 2357</td>\n",
       "      <td> 0.550705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PregnantNow</th>\n",
       "      <td>  883</td>\n",
       "      <td> 0.831681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0  missing_prop\n",
       "Race3             2508      0.521921\n",
       "Length             356      0.932139\n",
       "HeadCirc            61      0.988372\n",
       "BMICatUnder20yrs   724      0.861990\n",
       "Testosterone      2008      0.617232\n",
       "UrineVol2          763      0.854556\n",
       "UrineFlow2         763      0.854556\n",
       "DiabetesAge        330      0.937095\n",
       "nPregnancies      1283      0.755433\n",
       "nBabies           1182      0.774685\n",
       "Age1stBaby         941      0.820625\n",
       "PhysActiveDays    2374      0.547465\n",
       "TVHrsDay          2417      0.539268\n",
       "CompHrsDay        2419      0.538887\n",
       "TVHrsDayChild      417      0.920511\n",
       "CompHrsDayChild    417      0.920511\n",
       "AlcoholDay        2404      0.541746\n",
       "SmokeNow          1539      0.706634\n",
       "SmokeAge          1479      0.718071\n",
       "Marijuana         2411      0.540412\n",
       "AgeFirstMarij     1331      0.746283\n",
       "RegularMarij      2411      0.540412\n",
       "AgeRegMarij        629      0.880099\n",
       "SexNumPartYear    2405      0.541555\n",
       "SexOrientation    2357      0.550705\n",
       "PregnantNow        883      0.831681"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at columns missing data in > 50% of the observations\n",
    "df_missing_50 = df_count[df_count['missing_prop']>0.50]\n",
    "df_missing_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at those missing the most data, first thing that comes to mind that there is no way I should in anyway be involved in this part of the pipeline. I lack the necessary domain knowledge and proceeding forward would be extremely reckless.  \n",
    "\n",
    "Now I will proceed forward.  \n",
    "\n",
    "A data dictionary of some kind would also be helpful, but I'll guess at the columns' meaning.  \n",
    "Actually, any kind of analysis of above, and those that meet a higher threshold of missing data, will take a couple of hours at least, leaving little time for the rest of the midterm, so I guess that isn't an option.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And after a little deeper review of the data, my concerns are much deeper. Simply on that level it would be unwise to proceed - given an estimate of 6 hours for the midterm, I would think at least 4 should be spent on analyzing the data, much less any kind of imputation or filling missing values, and that is given my lack of domain knowledge. I'll probably wind up ruthlessly culling columns rather than going trying to fill any missing values.  \n",
    "  \n",
    "I consider pregnancy related columns to be one of the more important pieces of data that should be carefully considered, all things considered (effect on mother's overall health, effect on fetus health, term of pregnancy, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woman_childbearing_age = train[(train['Gender']=='female') & (train['Age'] > 14) & (train['Age'] < 50)]\n",
    "num_woman_childbearing_age = woman_childbearing_age.shape[0]\n",
    "num_woman_childbearing_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what percent of rows are really \"missing\" PregnantNow values\n",
      "28.56%\n"
     ]
    }
   ],
   "source": [
    "print 'what percent of rows are really \"missing\" PregnantNow values'\n",
    "print '{:.2f}%'.format((1-woman_childbearing_age['PregnantNow'].count()*1.0/num_woman_childbearing_age)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns for first pass\n",
    "- Age, is 100% filled, get rid of Age Decade, covered by Age, & AgeMonths, thats just going to add noise\n",
    "- Race1, Race3\n",
    "Socialogical factors that migh affect flu infection rates\n",
    "- Marital Status\n",
    "- HHIncome\n",
    "- Poverty\n",
    "- HHIncomeMid\n",
    "- HomeOwn\n",
    "- Work\n",
    "Bio factors\n",
    "- Weight\n",
    "- Height\n",
    "- BMI\n",
    "- Pulse\n",
    "- various BP\n",
    "    - Pulse\tBPSysAve\tBPDiaAve\tBPSys1\tBPDia1\tBPSys2\tBPDia2\tBPSys3\tBPDia3\n",
    "    \n",
    "Ok, this is silly, I'll just list the columns I'm going to use and try to fill in some justification later if time. Several relate to the idea that if someone has the flu they won't feel well.\n",
    "\n",
    "  \n",
    "ID  \n",
    "Gender  \n",
    "Age  \n",
    "Race1  \n",
    "Race3  \n",
    "Education  \n",
    "MaritalStatus  \n",
    "HHIncome  \n",
    "Poverty  \n",
    "HomeOwn  \n",
    "Work  \n",
    "Weight  \n",
    "Height  \n",
    "BMI  \n",
    "Pulse  \n",
    "BPSysAve  \n",
    "BPDiaAve  \n",
    "BPSys1  \n",
    "BPDia1  \n",
    "BPSys2  \n",
    "BPDia2  \n",
    "BPSys3  \n",
    "BPDia3  \n",
    "DirectChol  \n",
    "TotChol  \n",
    "UrineVol1  \n",
    "UrineFlow1  \n",
    "UrineVol2  \n",
    "UrineFlow2  \n",
    "Diabetes  \n",
    "HealthGen  \n",
    "DaysMentHlthBad  \n",
    "Depressed  \n",
    "SleepHrsNight  \n",
    "SleepTrouble  \n",
    "PhysActive  \n",
    "PhysActiveDays  \n",
    "SmokeNow  \n",
    "Marijuana  \n",
    "HardDrugs  \n",
    "PregnantNow  \n",
    "  \n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_columns = ['ID','Gender','Age','Race1','Race3','Education','MaritalStatus','HHIncome','Poverty','HomeOwn','Work',\n",
    "              'Weight','Height','BMI','Pulse','BPSysAve','BPDiaAve','BPSys1','BPDia1','BPSys2','BPDia2','BPSys3','BPDia3',\n",
    "              'DirectChol','TotChol','UrineVol1','UrineFlow1','UrineVol2','UrineFlow2','Diabetes','HealthGen',\n",
    "              'DaysMentHlthBad','Depressed','SleepHrsNight','SleepTrouble','PhysActive','PhysActiveDays','SmokeNow',\n",
    "              'Marijuana','HardDrugs','PregnantNow']\n",
    "\n",
    "train = train[keep_columns + ['flu','flutype']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>missing_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Race3</th>\n",
       "      <td> 2508</td>\n",
       "      <td> 0.521921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UrineVol2</th>\n",
       "      <td>  763</td>\n",
       "      <td> 0.854556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UrineFlow2</th>\n",
       "      <td>  763</td>\n",
       "      <td> 0.854556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActiveDays</th>\n",
       "      <td> 2374</td>\n",
       "      <td> 0.547465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SmokeNow</th>\n",
       "      <td> 1539</td>\n",
       "      <td> 0.706634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marijuana</th>\n",
       "      <td> 2411</td>\n",
       "      <td> 0.540412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PregnantNow</th>\n",
       "      <td>  883</td>\n",
       "      <td> 0.831681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0  missing_prop\n",
       "Race3           2508      0.521921\n",
       "UrineVol2        763      0.854556\n",
       "UrineFlow2       763      0.854556\n",
       "PhysActiveDays  2374      0.547465\n",
       "SmokeNow        1539      0.706634\n",
       "Marijuana       2411      0.540412\n",
       "PregnantNow      883      0.831681"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count = pd.DataFrame( train.count())\n",
    "df_count['missing_prop'] = df_count.apply(lambda cnt: 1-(cnt*1.0/train_size))\n",
    "\n",
    "missing_again = df_count[df_count['missing_prop'] > .50]\n",
    "missing_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_columns = list(missing_again.index.values)\n",
    "\n",
    "train = train.drop(drop_columns, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left with 36 columns\n",
      "\n",
      "['ID' 'Gender' 'Age' 'Race1' 'Education' 'MaritalStatus' 'HHIncome'\n",
      " 'Poverty' 'HomeOwn' 'Work' 'Weight' 'Height' 'BMI' 'Pulse' 'BPSysAve'\n",
      " 'BPDiaAve' 'BPSys1' 'BPDia1' 'BPSys2' 'BPDia2' 'BPSys3' 'BPDia3'\n",
      " 'DirectChol' 'TotChol' 'UrineVol1' 'UrineFlow1' 'Diabetes' 'HealthGen'\n",
      " 'DaysMentHlthBad' 'Depressed' 'SleepHrsNight' 'SleepTrouble' 'PhysActive'\n",
      " 'HardDrugs' 'flu' 'flutype']\n"
     ]
    }
   ],
   "source": [
    "final_columns = train.columns.values\n",
    "\n",
    "print 'left with {} columns'.format(len(train.columns.values))\n",
    "print\n",
    "print final_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO impute missing values ha ha, KNN is the only proper way, mean etc. all imply domain knowledge\n",
    "\n",
    "\n",
    "# for now, do this so things can actually finish... and anything fancier would need to be done on test set also\n",
    "# this is going to have to do, at the least want to turn 'DaysMentHlthBad' into some kind of binary or binned value\n",
    "train = train.fillna(train.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   int64\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Race1               object\n",
       "Education           object\n",
       "MaritalStatus       object\n",
       "HHIncome            object\n",
       "Poverty            float64\n",
       "HomeOwn             object\n",
       "Work                object\n",
       "Weight             float64\n",
       "Height             float64\n",
       "BMI                float64\n",
       "Pulse              float64\n",
       "BPSysAve           float64\n",
       "BPDiaAve           float64\n",
       "BPSys1             float64\n",
       "BPDia1             float64\n",
       "BPSys2             float64\n",
       "BPDia2             float64\n",
       "BPSys3             float64\n",
       "BPDia3             float64\n",
       "DirectChol         float64\n",
       "TotChol            float64\n",
       "UrineVol1          float64\n",
       "UrineFlow1         float64\n",
       "Diabetes            object\n",
       "HealthGen           object\n",
       "DaysMentHlthBad    float64\n",
       "Depressed           object\n",
       "SleepHrsNight      float64\n",
       "SleepTrouble        object\n",
       "PhysActive          object\n",
       "HardDrugs           object\n",
       "flu                  int64\n",
       "flutype              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the datatypes of remaining columns\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:200: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:1635: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 34 but corresponding boolean dimension is 36\n",
      "  sel[np.asarray(selected)] = True\n"
     ]
    }
   ],
   "source": [
    "# modified lab 10 code to encode the categorical variables via one-hot encoding\n",
    "\n",
    "#Encode categorical variables\n",
    "def encode_categorical(array):\n",
    "    if not array.dtype == np.dtype('float64'):\n",
    "        return preprocessing.LabelEncoder().fit_transform(array) \n",
    "    else:\n",
    "        return array\n",
    "    \n",
    "\n",
    "def prep_data(df, y_col_count):\n",
    "    to_float = df.dtypes[df.dtypes == 'int64'].index\n",
    "\n",
    "    # oops, this was a mistake in my first run, where not doing to_float resulted in better model\n",
    "    # Converted columns to floating point\n",
    "    for feature_name in to_float:\n",
    "        #if feature_name != 'ID':\n",
    "        df[feature_name] = df[feature_name].astype(float)\n",
    "\n",
    "    # Categorical columns for use in one-hot encoder\n",
    "    categorical = (df.dtypes.values != np.dtype('float64'))    \n",
    "    df = df.apply(encode_categorical)\n",
    "\n",
    "    if y_col_count:\n",
    "        # Get numpy array from data, we have two flu indicators in train\n",
    "        x = df.values[:, :-y_col_count]\n",
    "        y = df.values[:, -y_col_count:]\n",
    "    else:\n",
    "        x = df.values\n",
    "        y = None\n",
    "        \n",
    "    #print 'x.shape:',x.shape\n",
    "        \n",
    "    # Apply one hot endcoing\n",
    "    encoder = preprocessing.OneHotEncoder(categorical_features=categorical, sparse=False)  # Last value in mask is y\n",
    "    x = encoder.fit_transform(x)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = prep_data(train, y_col_count=2)\n",
    "#x_test, y_test = prep_data(test, y_col_count=0)\n",
    "\n",
    "y_train_p1 = y_train[: , 0]\n",
    "y_train_p2 = y_train[: , 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# below and several code snippets afterwards are from Lab10 notebook\n",
    "\n",
    "#Function for computing the accuracy a given model on the entire test set, the accuracy on class 0 in the test set\n",
    "#and the accuracy on class 1\n",
    "score = lambda model, x_test, y_test: pd.Series([model.score(x_test, y_test), \n",
    "                                                 model.score(x_test[y_test==0], y_test[y_test==0]),\n",
    "                                                 model.score(x_test[y_test==1], y_test[y_test==1])],\n",
    "                                                index=['overall accuracy', \n",
    "                                                       'accuracy on healthy patients', \n",
    "                                                       'accuracy on flu patients'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A model that labels everything 1\n",
    "class Pos_model(object):\n",
    "    def predict(self, x):\n",
    "        return np.array([1] * len(x))\n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "    \n",
    "#A model that labels everything 0\n",
    "class Neg_model(object):\n",
    "    def predict(self, x):\n",
    "        return np.array([0] * len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "\n",
    "\n",
    "#A model that randomly labels things\n",
    "class Random_model(object):\n",
    "    def predict(self, x):\n",
    "        return np.random.randint(0, 2, len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_model = Pos_model()\n",
    "pos_model_scores = score(pos_model, x_train, y_train_p1)\n",
    "\n",
    "neg_model = Neg_model()\n",
    "neg_model_scores = score(neg_model, x_train, y_train_p1)\n",
    "\n",
    "random_model = Random_model()\n",
    "random_model_scores = score(random_model, x_train, y_train_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg model</th>\n",
       "      <th>pos model</th>\n",
       "      <th>random model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall accuracy</th>\n",
       "      <td> 0.940907</td>\n",
       "      <td> 0.059093</td>\n",
       "      <td> 0.497713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on healthy patients</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.499595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on flu patients</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.490323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              neg model  pos model  random model\n",
       "overall accuracy               0.940907   0.059093      0.497713\n",
       "accuracy on healthy patients   1.000000   0.000000      0.499595\n",
       "accuracy on flu patients       0.000000   1.000000      0.490323"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score Dataframe\n",
    "score_df = pd.DataFrame({'pos model': pos_model_scores,\n",
    "                         'neg model': neg_model_scores,\n",
    "                         'random model': random_model_scores})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random baseline model, reports ~50% accuracy on healthy and on flu patients in observed data:\n",
      "  healthy patient accuracy 50%\n",
      "  flu patient accuracy     49%\n",
      "Assuming train and test are independent samples, it is a reasonable assumption that the \"Random\" baseline model\n",
      " perform just as well on future data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print 'random baseline model, reports ~50% accuracy on healthy and on flu patients in observed data:'\n",
    "print '  healthy patient accuracy {:.0f}%'.format(score_df.loc['accuracy on healthy patients'][2]*100)\n",
    "print '  flu patient accuracy     {:.0f}%'.format(score_df.loc['accuracy on flu patients'][2]*100)\n",
    "print 'Assuming train and test are independent samples, it is a reasonable assumption that the \"Random\" baseline model'\n",
    "print ' perform just as well on future data.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unweighted log\n",
      "weighted log\n",
      "lda\n",
      "qda\n",
      "tree\n",
      "rf\n",
      "knn\n"
     ]
    }
   ],
   "source": [
    "#Unweighted logistic regression\n",
    "unweighted_logistic = LogisticRegression()\n",
    "unweighted_logistic.fit(x_train, y_train_p1)\n",
    "\n",
    "unweighted_log_scores = score(unweighted_logistic, x_train, y_train_p1)\n",
    "print 'unweighted log'\n",
    "\n",
    "\n",
    "#Weighted logistic regression\n",
    "weighted_logistic = LogisticRegression(class_weight='balanced')\n",
    "weighted_logistic.fit(x_train, y_train_p1)\n",
    "\n",
    "weighted_log_scores = score(weighted_logistic, x_train, y_train_p1)\n",
    "print 'weighted log'\n",
    "\n",
    "#LDA\n",
    "lda = LDA()\n",
    "lda.fit(x_train, y_train_p1)\n",
    "\n",
    "lda_scores = score(lda, x_train, y_train_p1)\n",
    "print 'lda'\n",
    "\n",
    "#QDA\n",
    "qda = QDA()\n",
    "qda.fit(x_train, y_train_p1)\n",
    "\n",
    "qda_scores = score(qda, x_train, y_train_p1)\n",
    "print 'qda'\n",
    "\n",
    "#Decision Tree\n",
    "tree = DecisionTree(max_depth=6)\n",
    "tree.fit(x_train, y_train_p1)\n",
    "\n",
    "tree_scores = score(tree, x_train, y_train_p1)\n",
    "print 'tree'\n",
    "\n",
    "#Random Forest\n",
    "rf = RandomForest()\n",
    "rf.fit(x_train, y_train_p1)\n",
    "\n",
    "rf_scores = score(rf, x_train, y_train_p1)\n",
    "\n",
    "print 'rf'\n",
    "\n",
    "knn=KNN(25)\n",
    "knn.fit(x_train, y_train_p1)\n",
    "knn_scores = score(knn, x_train, y_train_p1)\n",
    "\n",
    "print 'knn'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>lda</th>\n",
       "      <th>qda</th>\n",
       "      <th>rf</th>\n",
       "      <th>tree</th>\n",
       "      <th>unweighted logistic</th>\n",
       "      <th>weighted logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall accuracy</th>\n",
       "      <td> 0.940907</td>\n",
       "      <td> 0.943195</td>\n",
       "      <td> 0.403736</td>\n",
       "      <td> 0.990469</td>\n",
       "      <td> 0.955204</td>\n",
       "      <td> 0.941860</td>\n",
       "      <td> 0.744186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on healthy patients</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.987034</td>\n",
       "      <td> 0.367504</td>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.999797</td>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.746759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on flu patients</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.245161</td>\n",
       "      <td> 0.980645</td>\n",
       "      <td> 0.838710</td>\n",
       "      <td> 0.245161</td>\n",
       "      <td> 0.016129</td>\n",
       "      <td> 0.703226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   knn       lda       qda        rf  \\\n",
       "overall accuracy              0.940907  0.943195  0.403736  0.990469   \n",
       "accuracy on healthy patients  1.000000  0.987034  0.367504  1.000000   \n",
       "accuracy on flu patients      0.000000  0.245161  0.980645  0.838710   \n",
       "\n",
       "                                  tree  unweighted logistic  weighted logistic  \n",
       "overall accuracy              0.955204             0.941860           0.744186  \n",
       "accuracy on healthy patients  0.999797             1.000000           0.746759  \n",
       "accuracy on flu patients      0.245161             0.016129           0.703226  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score Dataframe\n",
    "score_df = pd.DataFrame({#'knn': knn_scores, \n",
    "                         'unweighted logistic': unweighted_log_scores,\n",
    "                         'weighted logistic': weighted_log_scores,\n",
    "                         'lda': lda_scores,\n",
    "                         'qda': qda_scores,\n",
    "                         'tree': tree_scores,\n",
    "                         'rf': rf_scores,\n",
    "                         'knn': knn_scores})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted logistic regression had best accuracy, considering each of the two patient classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "overall accuracy                0.744186\n",
       "accuracy on healthy patients    0.746759\n",
       "accuracy on flu patients        0.703226\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Weighted logistic regression had best accuracy, considering each of the two patient classes'\n",
    "#Weighted logistic regression\n",
    "weighted_logistic = LogisticRegression(class_weight='balanced')\n",
    "weighted_logistic.fit(x_train, y_train_p1)\n",
    "\n",
    "weighted_log_scores = score(weighted_logistic, x_train, y_train_p1)\n",
    "weighted_log_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanity check the new split sizes\n",
      "(5246L, 84L) (5246L,)\n",
      "(3672L, 84L) (3672L,) (1574L, 84L) (1574L,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pull a validation set out of the 5k records in our train set, about 1600 records\n",
    "x_train_train, x_valid, y_train_train_p1, y_valid_p1 = sk_split(x_train, y_train_p1, test_size=0.30)\n",
    "\n",
    "print 'sanity check the new split sizes'\n",
    "print x_train.shape, y_train_p1.shape\n",
    "print x_train_train.shape, y_train_train_p1.shape, x_valid.shape, y_valid_p1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# I did try some tuning parameters on the logistic regression, using LogRegCV model but everything\n",
    "# I tried wound up doing worse when looking at accuracy within each class\n",
    "def nothing_doing():\n",
    "\n",
    "    #Generate array of L2 regularization parameters\n",
    "    regularization = 10.**np.arange(-10, 5)\n",
    "\n",
    "    #Fit logistic model with cross validation to select the optimal regularization parameter\n",
    "    logistic = LogRegCV(cv=5, \n",
    "                        penalty='l2', \n",
    "                        Cs=regularization, \n",
    "                        solver='liblinear', \n",
    "                        n_jobs=-1,\n",
    "                        class_weight='balanced')\n",
    "    #### all of train: logistic.fit(x_train, y_train_p1)\n",
    "    logistic.fit(x_train_train, y_train_train_p1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "overall accuracy                0.702668\n",
      "accuracy on healthy patients    0.710331\n",
      "accuracy on flu patients        0.580645\n",
      "dtype: float64\n",
      "0.0001\n",
      "overall accuracy                0.710928\n",
      "accuracy on healthy patients    0.722485\n",
      "accuracy on flu patients        0.526882\n",
      "dtype: float64\n",
      "0.001\n",
      "overall accuracy                0.736341\n",
      "accuracy on healthy patients    0.742066\n",
      "accuracy on flu patients        0.645161\n",
      "dtype: float64\n",
      "0.01\n",
      "overall accuracy                0.722363\n",
      "accuracy on healthy patients    0.725186\n",
      "accuracy on flu patients        0.677419\n",
      "dtype: float64\n",
      "0.1\n",
      "overall accuracy                0.708386\n",
      "accuracy on healthy patients    0.707630\n",
      "accuracy on flu patients        0.720430\n",
      "dtype: float64\n",
      "1.0\n",
      "overall accuracy                0.707116\n",
      "accuracy on healthy patients    0.707630\n",
      "accuracy on flu patients        0.698925\n",
      "dtype: float64\n",
      "10.0\n",
      "overall accuracy                0.705210\n",
      "accuracy on healthy patients    0.705604\n",
      "accuracy on flu patients        0.698925\n",
      "dtype: float64\n",
      "100.0\n",
      "overall accuracy                0.706480\n",
      "accuracy on healthy patients    0.706955\n",
      "accuracy on flu patients        0.698925\n",
      "dtype: float64\n",
      "1000.0\n",
      "overall accuracy                0.704574\n",
      "accuracy on healthy patients    0.705604\n",
      "accuracy on flu patients        0.688172\n",
      "dtype: float64\n",
      "10000.0\n",
      "overall accuracy                0.705210\n",
      "accuracy on healthy patients    0.705604\n",
      "accuracy on flu patients        0.698925\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# standard model, but train on new train & use out-of-sample validation set to score\n",
    "\n",
    "regularization = 10.**np.arange(-5, 5)\n",
    "\n",
    "for c in regularization:\n",
    "    weighted_logistic = LogisticRegression(class_weight='balanced', C=c)\n",
    "    weighted_logistic.fit(x_train_train, y_train_train_p1)\n",
    "\n",
    "    weighted_log_scores = score(weighted_logistic, x_valid, y_valid_p1)\n",
    "    print c\n",
    "    print weighted_log_scores\n",
    "\n",
    "#overall accuracy                0.741423\n",
    "#accuracy on healthy patients    0.747305\n",
    "#accuracy on flu patients        0.644444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy                0.705210\n",
      "accuracy on healthy patients    0.705604\n",
      "accuracy on flu patients        0.698925\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# for final model, go with C=10000\n",
    "final_log_model = LogisticRegression(class_weight='balanced', C=10000)\n",
    "final_log_model.fit(x_train_train, y_train_train_p1)\n",
    "\n",
    "final_log_scores = score(final_log_model, x_valid, y_valid_p1)\n",
    "print final_log_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv=5 (or 10), liblinear, balanced :\n",
    "    \n",
    "overall accuracy                0.745235\n",
    "accuracy on healthy patients    0.751020\n",
    "accuracy on flu patients        0.663462\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early test, replaced with version that has all written out\n",
    "\n",
    "def flu_predict_pass1(x_test):\n",
    "    cols = [col for col in x_test.columns if col in final_columns]\n",
    "    x_test = x_test[cols]\n",
    "    x_test = x_test.fillna(test.mean())\n",
    "    x_test_prepped, y_test = prep_data(x_test, y_col_count=0)\n",
    "    \n",
    "    pred = final_log_model.predict(x_test_prepped)\n",
    "    \n",
    "    return pred\n",
    "    \n",
    "#final_log_model.predict(x_test)\n",
    "#x_test, y_test = prep_data(test, y_col_count=0)\n",
    "\n",
    "predictions = flu_predict_pass1(test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flu_predict(x_test):\n",
    "    \n",
    "    #Encode categorical variables\n",
    "    def encode_categorical(array):\n",
    "        if not array.dtype == np.dtype('float64'):\n",
    "            return preprocessing.LabelEncoder().fit_transform(array) \n",
    "        else:\n",
    "            return array\n",
    "    \n",
    "    cols = [col for col in x_test.columns if col in final_columns]\n",
    "    x_test = x_test[cols]\n",
    "    x_test = x_test.fillna(test.mean()) \n",
    "\n",
    "    to_float = x_test.dtypes[x_test.dtypes == 'int64'].index\n",
    "    # Converted columns to floating point\n",
    "    for feature_name in to_float:\n",
    "        #if feature_name != 'ID':\n",
    "        x_test[feature_name] = x_test[feature_name].astype(float)\n",
    "\n",
    "    # Categorical columns for use in one-hot encoder\n",
    "    categorical = (x_test.dtypes.values != np.dtype('float64'))    \n",
    "    x_test = x_test.apply(encode_categorical)\n",
    "   \n",
    "    x = x_test.values\n",
    "\n",
    "    # Apply one hot endcoing\n",
    "    encoder = preprocessing.OneHotEncoder(categorical_features=categorical, sparse=False)  # Last value in mask is y\n",
    "    x = encoder.fit_transform(x)\n",
    "\n",
    "    pred = final_log_model.predict(x)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "\n",
    "#predictions = flu_predict(test)\n",
    "#predictions[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 1010, 1.0: 523})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>flu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 51625</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 51678</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 51694</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 51695</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 51711</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  flu\n",
       "0  51625    0\n",
       "1  51678    1\n",
       "2  51694    1\n",
       "3  51695    1\n",
       "4  51711    1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions using above function, take a peek at per-flu counts\n",
    "predictions = flu_predict(test)\n",
    "print collections.Counter(predictions)\n",
    "\n",
    "# write to file\n",
    "out = np.column_stack((test['ID'].values, predictions))\n",
    "np.savetxt('p1_out.csv', out, delimiter=',', header='ID,flu', comments='')\n",
    "\n",
    "back_in = pd.read_csv('p1_out.csv', low_memory=False)  \n",
    "back_in.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Diagnosing Strains of the Semian Flu\n",
    "\n",
    "From a public health perspective, we want to balance the cost of vaccinations, early interventions and the cost of treating flu complications of unvaccinated people. \n",
    "\n",
    "There are two different strains of the flu: strain 1 has a cheaper early intervention as well as a cheaper treatment for flu complications, but patients with strain 1 has a higher rate of developing complications if treated with the wrong intervention. Strain 2 has a more expensive early intervention as well as a more costly treatment for flu complications, but patients with strain 2 has a lower rate of developing complications if treated with the wrong intervention. With no intervention, flu patients develop complications at the same rate regardless of the strain. \n",
    "\n",
    "**Your task:** build a model to predict if a given patient has the flu and identify the flu strain. The state government of MA will use your model to inform public health policies: we will vaccinate people you've identified as healthy and apply corresponding interventions to patients with different strains of the flu. We have provided you with a function to compute the total expected cost of this policy decision that takes into account the cost of the vaccine, the interventions and the cost of the treatments for flu complications resulting from misdiagnosing patients. Your goal is to make sure your model produces a public health policy with the lowest associated expected cost.\n",
    "\n",
    "**The deliverable:** a function called `flu_predict` which satisfies:\n",
    "\n",
    "- input: `x_test`, a set of medical predictors for a group of patients\n",
    "- output: `y_pred`, a set of labels, one for each patient; 1 for healthy, 2 for infected with strain 1, and 3 for infected with strain 2.\n",
    "\n",
    "The MA state government will use your model to diagnose sets of future patients (held by us). You can expect that there will be an increase in the number of flu patients in any groups of patients in the future.\n",
    "\n",
    "We provide you with some benchmarks for comparison.\n",
    "\n",
    "**Three Baseline Models:** \n",
    "- expected cost on observed data: \\$6,818,206.0, \\$7,035,735.0, \\$8,297,197.5\n",
    "- time to build: 1 min\n",
    "\n",
    "**Reasonable Model:** \n",
    "- expected cost on observed data: $6,300,000\n",
    "- time to build: 20 min\n",
    "\n",
    "**Grading:**\n",
    "Your grade will be based on:\n",
    "1. your model's ability to out-perform our benchmarks\n",
    "2. your ability to carefully and thoroughly follow the data science pipeline (see lecture slides for definition)\n",
    "3. the extend to which all choices are reasonable and defensible by methods you have learned in this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------  cost\n",
    "# A function that computes the expected cost of the public healthy policy based on the \n",
    "# classifications generated by your model\n",
    "# Input: \n",
    "#      y_true (true class labels)\n",
    "#      y_pred (predicted class labels)\n",
    "# Returns: \n",
    "#      total_cost (expected total cost)\n",
    "\n",
    "def cost(y_true, y_pred):\n",
    "    # set a seed, can't get repeatable results without it\n",
    "    np.random.seed(109)\n",
    "    cost_of_treatment_1 = 29500\n",
    "    cost_of_treatment_2 = 45000\n",
    "    cost_of_intervention_1 = 4150\n",
    "    cost_of_intervention_2 = 4250\n",
    "    cost_of_vaccine = 15\n",
    "    \n",
    "    prob_complications_untreated = 0.65\n",
    "    prob_complications_1 = 0.30\n",
    "    prob_complications_2 = 0.15\n",
    "    \n",
    "    trials = 1000\n",
    "    \n",
    "    \n",
    "    intervention_cost = cost_of_intervention_1 * len(y_pred[y_pred==1]) + cost_of_intervention_2 * len(y_pred[y_pred==2])\n",
    "\n",
    "    vaccine_cost = cost_of_vaccine * len(y_pred[y_pred==0])\n",
    "    \n",
    "    false_neg_1 = ((y_true == 1) & (y_pred == 2)).sum()\n",
    "    false_neg_2 = ((y_true == 2) & (y_pred == 1)).sum()\n",
    "    \n",
    "    untreated_1 = ((y_true == 1) & (y_pred == 0)).sum()    \n",
    "    untreated_2 = ((y_true == 2) & (y_pred == 0)).sum()\n",
    "    \n",
    "    false_neg_1_cost = np.random.binomial(1, prob_complications_1, (false_neg_1, trials)) * cost_of_treatment_1\n",
    "    false_neg_2_cost = np.random.binomial(1, prob_complications_2, (false_neg_2, trials)) * cost_of_treatment_2\n",
    "    untreated_1_cost = np.random.binomial(1, prob_complications_untreated, (untreated_1, trials)) * cost_of_treatment_1\n",
    "    untreated_2_cost = np.random.binomial(1, prob_complications_untreated, (untreated_2, trials)) * cost_of_treatment_2\n",
    "    \n",
    "    false_neg_1_cost = false_neg_1_cost.sum(axis=0)\n",
    "    expected_false_neg_1_cost = false_neg_1_cost.mean()\n",
    "    \n",
    "    false_neg_2_cost = false_neg_2_cost.sum(axis=0)\n",
    "    expected_false_neg_2_cost = false_neg_2_cost.mean()\n",
    "    \n",
    "    untreated_1_cost = untreated_1_cost.sum(axis=0)\n",
    "    expected_untreated_1_cost = untreated_1_cost.mean()\n",
    "    \n",
    "    untreated_2_cost = untreated_2_cost.sum(axis=0)\n",
    "    expected_untreated_2_cost = untreated_2_cost.mean()\n",
    "    \n",
    "    total_cost = vaccine_cost + intervention_cost + expected_false_neg_1_cost + expected_false_neg_2_cost + expected_untreated_1_cost + expected_untreated_2_cost\n",
    "    \n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't know if I'm supposed to try to implement any baseline models but for the life of me I can't figure out the meaning of below so, I guess it isn't going to happen (supposing it was supposed to happen):   \n",
    "\n",
    "> expected cost on observed data: \\$6,818,206.0, \\$7,035,735.0, \\$8,297,197.5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 4936, 2.0: 227, 3.0: 83})\n",
      "Counter({0.0: 4936, 1.0: 227, 2.0: 83})\n"
     ]
    }
   ],
   "source": [
    "# re-set\n",
    "y_train_p2_orig = y_train[: ,1]\n",
    "\n",
    "# check out the per-flutype counts\n",
    "print collections.Counter(y_train_p2_orig)\n",
    "# normalize the flutype values to what cost() function expects\n",
    "y_train_p2 = np.array(y_train_p2_orig)\n",
    "y_train_p2 -= 1\n",
    "# print out conformed counts\n",
    "print collections.Counter(y_train_p2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      unweighted log:  $6,784,932.0\n",
      "        weighted log:  $6,279,829.5\n",
      "                 lda:  $6,058,950.0\n",
      "                 qda:  $15,005,502.0\n",
      "                tree:  $5,692,421.5\n",
      "                  rf:  $2,173,663.5\n",
      "                 knn:  $6,859,270.5\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:453: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# run through each model, training on 2nd dependent variable, y_train_p2 aka flutype\n",
    "costs = collections.OrderedDict()\n",
    "\n",
    "#Unweighted logistic regression\n",
    "unweighted_logistic = LogisticRegression()\n",
    "unweighted_logistic.fit(x_train, y_train_p2)\n",
    "y_pred = unweighted_logistic.predict(x_train)\n",
    "mod = 'unweighted log'\n",
    "costs[mod] = cost(y_train_p2, y_pred)\n",
    "\n",
    "#Weighted logistic regression\n",
    "weighted_logistic = LogisticRegression(class_weight='balanced')\n",
    "weighted_logistic.fit(x_train, y_train_p2)\n",
    "y_pred = weighted_logistic.predict(x_train)\n",
    "mod = 'weighted log'\n",
    "costs[mod] = cost(y_train_p2, y_pred)\n",
    "\n",
    "#LDA\n",
    "lda = LDA()\n",
    "lda.fit(x_train, y_train_p2)\n",
    "y_pred = lda.predict(x_train)\n",
    "mod = 'lda'\n",
    "costs[mod] = cost(y_train_p2, y_pred)\n",
    "\n",
    "#QDA\n",
    "qda = QDA()\n",
    "qda.fit(x_train, y_train_p2)\n",
    "y_pred = qda.predict(x_train)\n",
    "mod = 'qda'\n",
    "costs[mod] = cost(y_train_p2, y_pred)\n",
    "\n",
    "#Decision Tree\n",
    "tree = DecisionTree(max_depth=6)\n",
    "tree.fit(x_train, y_train_p2)\n",
    "y_pred = tree.predict(x_train)\n",
    "mod = 'tree'\n",
    "costs[mod] = cost(y_train_p2, y_pred)\n",
    "\n",
    "#Random Forest\n",
    "rf = RandomForest()\n",
    "rf.fit(x_train, y_train_p2)\n",
    "y_pred = rf.predict(x_train)\n",
    "mod = 'rf'\n",
    "costs[mod] = cost(y_train_p2, y_pred)\n",
    "\n",
    "#KNN\n",
    "knn=KNN(25)\n",
    "knn.fit(x_train, y_train_p2)\n",
    "y_pred = knn.predict(x_train)\n",
    "mod = 'knn'\n",
    "costs[mod] = cost(y_train_p2, y_pred)\n",
    "\n",
    "\n",
    "for mod, total_cost in costs.iteritems():\n",
    "    print '{:>20}:  ${:,}'.format(mod, total_cost)\n",
    "    \n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the implementations, Random Forest would appear to be the clear winner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set, get each prediction correct and cost will be: $1,368,840.0\n"
     ]
    }
   ],
   "source": [
    "print 'train set, get each prediction correct and cost will be: ${:,}'.format(cost(y_train_p2, y_train_p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "Trees: 20 Depth: 300 Cost: 1344374.1\n",
      "Trees: 20 Depth: 400 Cost: 1346328.3\n",
      "Trees: 20 Depth: 500 Cost: 1369303.1\n",
      "Trees: 20 Depth: 600 Cost: 1344525.7\n",
      "Trees: 20 Depth: 700 Cost: 1363439.0\n",
      "Trees: 20 Depth: 800 Cost: 1347602.7\n",
      "Trees: 20 Depth: 900 Cost: 1354489.0\n",
      "Trees: 20 Depth: 1000 Cost: 1344525.7\n",
      "Trees: 20 Depth: 1100 Cost: 1363439.0\n",
      "Trees: 40 Depth: 300 Cost: 1355080.9\n",
      "Trees: 40 Depth: 400 Cost: 1361303.8\n",
      "Trees: 40 Depth: 500 Cost: 1354691.8\n",
      "Trees: 40 Depth: 600 Cost: 1341031.8\n",
      "Trees: 40 Depth: 700 Cost: 1355259.0\n",
      "Trees: 40 Depth: 800 Cost: 1339049.5\n",
      "Trees: 40 Depth: 900 Cost: 1365921.0\n",
      "Trees: 40 Depth: 1000 Cost: 1355259.0\n",
      "Trees: 40 Depth: 1100 Cost: 1339049.5\n",
      "Trees: 60 Depth: 300 Cost: 1352953.2\n",
      "Trees: 60 Depth: 400 Cost: 1361071.1\n",
      "Trees: 60 Depth: 500 Cost: 1358822.8\n",
      "Trees: 60 Depth: 600 Cost: 1348317.8\n",
      "Trees: 60 Depth: 700 Cost: 1359447.5\n",
      "Trees: 60 Depth: 800 Cost: 1361017.8\n",
      "Trees: 60 Depth: 900 Cost: 1363121.4\n",
      "Trees: 60 Depth: 1000 Cost: 1356310.8\n",
      "Trees: 60 Depth: 1100 Cost: 1346734.9\n",
      "Chosen number of trees, depth: 40 , 800\n"
     ]
    }
   ],
   "source": [
    "# adapted from HW7 solutions, do some parameter tuning \n",
    "\n",
    "# Parameters for tuning\n",
    "n_trees = np.arange(20, 80, 20)  # Trees and depth are explored on an exponentially growing space,\n",
    "\n",
    "depths = np.arange(2, 10)   # since it is assumed that trees and depth will add accuracy in a decaying fashion.\n",
    "depths = np.arange(300, 1200, 100)   # since it is assumed that trees and depth will add accuracy in a decaying fashion.\n",
    "\n",
    "\n",
    "# To keep track of the best model\n",
    "best_score = 0\n",
    "best_cost = 999999999\n",
    "\n",
    "# Run grid search for model with 5-fold cross validation\n",
    "print '5-fold cross validation:'\n",
    "\n",
    "for trees in n_trees:\n",
    "    for depth in depths:\n",
    "        \n",
    "        # Cross validation for every experiment\n",
    "        k_folds = KFold(x_train.shape[0], n_folds=5, shuffle=True)\n",
    "        scores = []\n",
    "        costs = []\n",
    "        for train_indices, validation_indices in k_folds:\n",
    "            # Generate training data\n",
    "            x_train_cv = x_train[train_indices]\n",
    "            y_train_cv = y_train_p2[train_indices]\n",
    "            # Generate validation data\n",
    "            x_validate = x_train[validation_indices]\n",
    "            y_validate = y_train_p2[validation_indices]\n",
    "            \n",
    "            # Fit random forest on training data\n",
    "            model = RandomForest(n_estimators=trees, max_depth=depth)\n",
    "            model.fit(x_train_cv, y_train_cv)\n",
    "            # Score on validation data\n",
    "            scores += [model.score(x_validate, y_validate)]\n",
    "            \n",
    "            y_pred = model.predict(x_validate)\n",
    "            costs += [cost(y_validate, y_pred)]\n",
    "        \n",
    "        # Record and report accuracy\n",
    "        average_score = np.mean(scores)\n",
    "        average_cost = np.mean(costs)\n",
    "        #print \"Trees:\", trees, \"Depth:\", depth, \"(irrelevant) Score:\", average_score\n",
    "        print \"Trees:\", trees, \"Depth:\", depth, \"Cost:\", average_cost\n",
    "\n",
    "        # Update our record of the best parameters see so far\n",
    "        if average_cost < best_cost:\n",
    "            best_cost = average_cost\n",
    "            best_trees = trees\n",
    "            best_depth = depth\n",
    "            \n",
    "# Fit model on entire train set using chosen number of trees and depth\n",
    "final_model_p2 = RandomForest(n_estimators=best_trees, max_depth=best_depth)\n",
    "final_model_p2.fit(x_train, y_train_p2)\n",
    "\n",
    "print 'Chosen number of trees, depth:', best_trees, ',', best_depth\n",
    "#print 'Test accuracy:', final_model_p2.score(x_train, y_train_p2)\n",
    "\n",
    "\n",
    "# Chosen number of trees, depth: 50 , 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_trees: 40  best_depth: 800\n",
      "1,458,696.5\n",
      "Counter({0.0: 4942, 1.0: 221, 2.0: 83})\n"
     ]
    }
   ],
   "source": [
    "final_model_p2 = RandomForest(n_estimators=best_trees, max_depth=best_depth)\n",
    "final_model_p2.fit(x_train, y_train_p2)\n",
    "\n",
    "# lets look at cost of that final model\n",
    "y_pred_model = final_model_p2.predict(x_train)\n",
    "print 'best_trees: {}  best_depth: {}'.format(best_trees, best_depth)\n",
    "print '{:,}'.format(cost(y_train_p2, y_pred_model))\n",
    "\n",
    "# take a look at the per-flutype counts\n",
    "print collections.Counter(y_pred_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "until a late breaking change I made somewhere, 50, 1000 were the parameters that were working best\n",
      " the cost was notably lower than what I am coming up with now\n",
      "best_trees: 40  best_depth: 800\n",
      "1,424,313.5\n",
      "Counter({0.0: 4939, 1.0: 225, 2.0: 82})\n"
     ]
    }
   ],
   "source": [
    "print 'until a late breaking change I made somewhere, 50, 1000 were the parameters that were working best'\n",
    "print ' the cost was notably lower than what I am coming up with now'\n",
    "# @ 50, 1000, this was working best during my testing\n",
    "#best_trees: 50  best_depth: 1000\n",
    "#1,424,313.5\n",
    "#Counter({0.0: 4939, 1.0: 225, 2.0: 82})\n",
    "\n",
    "\n",
    "my_best_trees = 50\n",
    "my_best_depth = 1000\n",
    "\n",
    "my_model = RandomForest(n_estimators=my_best_trees, max_depth=my_best_depth)\n",
    "my_model.fit(x_train, y_train_p2)\n",
    "\n",
    "# lets look at cost of that final model\n",
    "y_pred_my_model = my_model.predict(x_train)\n",
    "print 'best_trees: {}  best_depth: {}'.format(best_trees, best_depth)\n",
    "print '{:,}'.format(cost(y_train_p2, y_pred_my_model))\n",
    "\n",
    "# take a look at the per-flutype counts\n",
    "print collections.Counter(y_pred_my_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so I am going to use what was working previously for me, that is just the way it is going to be\n",
      "since those were the values my following testing were based off of\n",
      "best_trees: 50  best_depth: 1000\n",
      "1,428,705.0\n",
      "Counter({0.0: 4940, 1.0: 223, 2.0: 83})\n"
     ]
    }
   ],
   "source": [
    "print 'so I am going to use what was working previously for me, that is just the way it is going to be'\n",
    "print 'since those were the values my following testing were based off of'\n",
    "\n",
    "# hard code in the numbers to make it clear what I am doing\n",
    "final_model_p2 = RandomForest(n_estimators=50, max_depth=1000)\n",
    "final_model_p2.fit(x_train, y_train_p2)\n",
    "\n",
    "# lets look at cost of that final model\n",
    "y_pred_model = final_model_p2.predict(x_train)\n",
    "print 'best_trees: {}  best_depth: {}'.format(50, 1000)\n",
    "print '{:,}'.format(cost(y_train_p2, y_pred_model))\n",
    "\n",
    "# take a look at the per-flutype counts\n",
    "print collections.Counter(y_pred_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature count: 5  cost: 1,424,313.5\n",
      "feature count: 6  cost: 1,452,955.0\n",
      "feature count: 7  cost: 1,438,432.0\n",
      "feature count: 8  cost: 1,438,432.0\n",
      "feature count: 9  cost: 1,424,313.5\n",
      "feature count: 10  cost: 1,478,600.0\n",
      "feature count: 11  cost: 1,443,243.5\n",
      "feature count: 12  cost: 1,448,608.5\n",
      "feature count: 13  cost: 1,462,682.0\n"
     ]
    }
   ],
   "source": [
    "# didn't have time to formally insert into the tuning run a few cells above but now that we have a depth & n_estimators\n",
    "#  take moment to see if some manual max_feature setting will help out\n",
    "feature_base = int(np.sqrt(x_train.shape[1]))\n",
    "for feature_count in range(feature_base-4, feature_base+5):\n",
    "    rf_model = RandomForest(n_estimators=best_trees, max_depth=best_depth, max_features=feature_count)\n",
    "    rf_model.fit(x_train, y_train_p2)\n",
    "    y_pred = rf_model.predict(x_train)\n",
    "    print 'feature count: {}  cost: {:,}'.format(feature_count, cost(y_train_p2, y_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_trees: 40  best_depth:800  best_max_features: 8\n",
      "cost now, observerd data: $1,438,432.0\n",
      "prediction breakdown: Counter({0.0: 4940, 1.0: 224, 2.0: 82})\n"
     ]
    }
   ],
   "source": [
    "# above seemed to indicate decreasing max_features a bit from the default might help out, toss that in to final\n",
    "# (or it clearly did in my earlier tests, of course that shifted a bit)\n",
    "best_max_features = 8\n",
    "final_model_p2 = RandomForest(n_estimators=best_trees, max_depth=best_depth, max_features=best_max_features)\n",
    "final_model_p2.fit(x_train, y_train_p2)\n",
    "# y_pred = final_model_p2.predict(x_train)\n",
    "y_pred_model = final_model_p2.predict(x_train)\n",
    "\n",
    "print 'best_trees: {}  best_depth:{}  best_max_features: {}'.format(best_trees, best_depth, best_max_features)\n",
    "print 'cost now, observerd data: ${:,}'.format(cost(y_train_p2, y_pred_model))\n",
    "\n",
    "print 'prediction breakdown: {}'.format(collections.Counter(y_pred_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1533L, 84L)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 1520, 1.0: 10, 2.0: 3})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# early test, replaced with written out version\n",
    "\n",
    "def flu_predict_p2_first_pass(x_test):\n",
    "    cols = [col for col in x_test.columns if col in final_columns]\n",
    "    x_test = x_test[cols]\n",
    "    x_test = x_test.fillna(test.mean())\n",
    "    x_test_prepped, y_test = prep_data(x_test, y_col_count=0)\n",
    "    \n",
    "    print x_test_prepped.shape\n",
    "    pred = final_model_p2.predict(x_test_prepped)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "predictions_p2 = flu_predict_p2_first_pass(test)\n",
    "collections.Counter(predictions_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 1520, 1.0: 10, 2.0: 3})\n"
     ]
    }
   ],
   "source": [
    "def flu_predict(x_test):\n",
    "    \n",
    "    #Encode categorical variables\n",
    "    def encode_categorical(array):\n",
    "        if not array.dtype == np.dtype('float64'):\n",
    "            return preprocessing.LabelEncoder().fit_transform(array) \n",
    "        else:\n",
    "            return array\n",
    "    \n",
    "    cols = [col for col in x_test.columns if col in final_columns]\n",
    "    x_test = x_test[cols]\n",
    "    x_test = x_test.fillna(test.mean()) \n",
    "\n",
    "    to_float = x_test.dtypes[x_test.dtypes == 'int64'].index\n",
    "    # Converted columns to floating point\n",
    "    for feature_name in to_float:\n",
    "        #if feature_name != 'ID':\n",
    "        x_test[feature_name] = x_test[feature_name].astype(float)\n",
    "\n",
    "    # Categorical columns for use in one-hot encoder\n",
    "    categorical = (x_test.dtypes.values != np.dtype('float64'))    \n",
    "    x_test = x_test.apply(encode_categorical)\n",
    "   \n",
    "    x = x_test.values\n",
    "\n",
    "    # Apply one hot endcoing\n",
    "    encoder = preprocessing.OneHotEncoder(categorical_features=categorical, sparse=False)  # Last value in mask is y\n",
    "    x = encoder.fit_transform(x)\n",
    "\n",
    "    # final model determined via CV & param tuning\n",
    "    pred = final_model_p2.predict(x)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "# quick check\n",
    "print collections.Counter(flu_predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 1520, 1.0: 10, 2.0: 3})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>flutype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 51625</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 51678</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 51694</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 51695</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 51711</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  flutype\n",
       "0  51625        0\n",
       "1  51678        0\n",
       "2  51694        0\n",
       "3  51695        0\n",
       "4  51711        0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# very low prediction counts for has-flu flu strains, no time to re-investigate\n",
    "predictions_p2 = flu_predict(test)\n",
    "print collections.Counter(predictions_p2)\n",
    "\n",
    "# write to file\n",
    "out = np.column_stack((test['ID'].values, predictions_p2))\n",
    "np.savetxt('p2_out.csv', out, delimiter=',', header='ID,flutype', comments='')\n",
    "\n",
    "back_in = pd.read_csv('p2_out.csv', low_memory=False)  \n",
    "back_in.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
